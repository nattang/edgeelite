#!/usr/bin/env python3
"""
Setup Llama-v3.2-3B-Instruct in LM Studio for EdgeElite AI Assistant
This script helps you configure LM Studio to use Llama-v3.2-3B-Instruct.
"""

import sys
import os

def show_setup_instructions():
    """Show detailed setup instructions for Llama-v3.2-3B-Instruct in LM Studio."""
    print("üöÄ Setting up Llama-v3.2-3B-Instruct in LM Studio for EdgeElite")
    print("=" * 80)
    
    print("\nüìã Step-by-Step Setup Instructions:")
    print("=" * 50)
    
    print("\n1Ô∏è‚É£ Download and Install LM Studio")
    print("   ‚Ä¢ Visit: https://lmstudio.ai/")
    print("   ‚Ä¢ Download and install LM Studio")
    print("   ‚Ä¢ Launch LM Studio")
    
    print("\n2Ô∏è‚É£ Download Llama-v3.2-3B-Instruct")
    print("   ‚Ä¢ In LM Studio, go to 'Search' tab")
    print("   ‚Ä¢ Search for: 'llama-v3.2-3b-instruct'")
    print("   ‚Ä¢ Look for: 'llama-v3.2-3b-instruct' by Meta")
    print("   ‚Ä¢ Click 'Download' (size: ~2GB)")
    print("   ‚Ä¢ Wait for download to complete")
    
    print("\n3Ô∏è‚É£ Load the Model")
    print("   ‚Ä¢ Go to 'Local Server' tab")
    print("   ‚Ä¢ Find 'llama-v3.2-3b-instruct' in your models")
    print("   ‚Ä¢ Click 'Load' to load the model")
    print("   ‚Ä¢ Wait for model to load (may take a few minutes)")
    
    print("\n4Ô∏è‚É£ Enable API Server")
    print("   ‚Ä¢ Go to 'Settings' tab")
    print("   ‚Ä¢ Click on 'API Server' in the left sidebar")
    print("   ‚Ä¢ Check 'Start API Server'")
    print("   ‚Ä¢ Note the URL (default: http://localhost:1234)")
    print("   ‚Ä¢ Click 'Save'")
    
    print("\n5Ô∏è‚É£ Test Connection")
    print("   ‚Ä¢ Run: python test_lm_studio.py")
    print("   ‚Ä¢ Should show: '‚úÖ Successfully connected to LM Studio!'")
    print("   ‚Ä¢ Should show: 'llama-v3.2-3b-instruct' in available models")
    
    print("\n6Ô∏è‚É£ Start EdgeElite Backend")
    print("   ‚Ä¢ Run: python main.py")
    print("   ‚Ä¢ Should show: '‚úÖ Connected to LM Studio - Using remote models!'")
    print("   ‚Ä¢ Your EdgeElite AI Assistant is now using Llama-v3.2-3B-Instruct!")
    
    print("\nüéØ Model Specifications:")
    print("   ‚Ä¢ Model: Llama-v3.2-3B-Instruct")
    print("   ‚Ä¢ Parameters: 3.2B (much better than 117M small model)")
    print("   ‚Ä¢ Context: 4096 tokens")
    print("   ‚Ä¢ Quality: High-quality instruction-tuned responses")
    print("   ‚Ä¢ Speed: Fast inference via LM Studio")
    print("   ‚Ä¢ Storage: No local storage needed")
    
    print("\nüí° Benefits of Llama-v3.2-3B-Instruct:")
    print("   ‚Ä¢ Much better response quality than small models")
    print("   ‚Ä¢ Instruction-tuned for better chat responses")
    print("   ‚Ä¢ Longer context window (4096 tokens)")
    print("   ‚Ä¢ Better understanding of complex queries")
    print("   ‚Ä¢ More natural and helpful responses")
    print("   ‚Ä¢ Optimized for edge devices")
    
    print("\nüîß Troubleshooting:")
    print("   ‚Ä¢ If connection fails, check LM Studio is running")
    print("   ‚Ä¢ If model not found, make sure it's downloaded and loaded")
    print("   ‚Ä¢ If API server not working, check settings")
    print("   ‚Ä¢ Default URL should be: http://localhost:1234")
    
    print("\nüéâ Once setup is complete, your EdgeElite AI Assistant will:")
    print("   ‚Ä¢ Use Llama-v3.2-3B-Instruct for all responses")
    print("   ‚Ä¢ Provide high-quality AI insights")
    print("   ‚Ä¢ Handle complex queries better")
    print("   ‚Ä¢ Give more natural and helpful responses")
    print("   ‚Ä¢ Work seamlessly with your Snapdragon X-Elite")

def check_current_status():
    """Check current LM Studio connection status."""
    print("\nüîç Checking Current Status:")
    print("=" * 30)
    
    try:
        from lm_studio_client import lm_studio_client
        
        status = lm_studio_client.get_status()
        
        if status["connected"]:
            print("‚úÖ LM Studio is connected!")
            print(f"üìç URL: {status['base_url']}")
            print(f"üìä Available models: {status['available_models']}")
            
            if "llama-v3.2-3b-instruct" in str(status["models"]):
                print("‚úÖ Llama-v3.2-3B-Instruct is available!")
                print("üéâ Your EdgeElite AI Assistant is ready to use Llama-v3.2-3B-Instruct!")
            else:
                print("‚ö†Ô∏è Llama-v3.2-3B-Instruct not found in available models")
                print("   Please download and load the model in LM Studio")
        else:
            print("‚ùå LM Studio is not connected")
            print("   Please follow the setup instructions above")
            
    except ImportError:
        print("‚ùå LM Studio client not available")
    except Exception as e:
        print(f"‚ùå Error checking status: {e}")

def main():
    """Main function."""
    print("EdgeElite AI Assistant - Llama-v3.2-3B-Instruct Setup")
    print("For Qualcomm HaQathon - High-Quality Edge AI")
    print()
    
    show_setup_instructions()
    check_current_status()
    
    print("\n" + "=" * 80)
    print("üöÄ Ready to set up Llama-v3.2-3B-Instruct for EdgeElite!")
    print("Follow the instructions above to get high-quality AI responses.")

if __name__ == "__main__":
    main() 